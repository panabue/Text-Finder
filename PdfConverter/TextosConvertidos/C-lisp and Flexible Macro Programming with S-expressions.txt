arXiv:2410.16690v2  [cs.PL]  23 Oct 2024
C-lisp and Flexible Macro Programming with S-expressions
Vedanth Padmaraman, Sasank Chilamkurthy
Abstract
Llama.lisp is a compiler framework intended to target oﬄoad processor backends such as GPUs, using
intermediate representation languages (IRs) that are device-agnostic. The Llama.lisp IRs are formulated
as S-expressions. This makes them easy to generate using higher level programming languages, which
is one of the primary goals for Llama.lisp. The highest IR layer currently implemented in Llama.lisp is
C-Lisp. In this paper, we describe the macro system developed for the Llama.lisp compiler framework.
We show how we implemented FFI bindings as an example of this system.
Compilers are workhorses of performance behind all AI algorithms. Making algorithms work eﬀectively on
GPUs is especially hard – called kernel programming. The compiler ecosystem around GPUs is especially
fragmented. They are supposed to allow for performance portability between diﬀerent hardware architecture.
Unfortunately, this is usually not the case.
We are designing a compiler framework called llama.lisp [1] to solve this problem. As suggested by the
name, the framework is highly inspired by Lisp and its syntax, S-expressions. A multi layered approach is
adopted to tame the complexity of writing such a compiler framework. We implement C-lisp as one such
layer. We show how lisp syntax has allowed for unique meta programming capabilities while being simple
both to understand and implement.
1. C-Lisp: Structured LLVM IR
C-Lisp serves as a structured programming [2] interface to the LLVM [3] instruction set, with semantics
modelled after the C language [4]. The S-expression syntax forms the base of the C-Lisp syntax. An S-
expression can be either a token or a list, the elements of which are also S-expressions. The ﬁrst element of
a list usually speciﬁes an action (in which case it is a token), and the remainder of the elements specify the
arguments to that action. By a slight extension of logic, S-expressions can also be viewed as trees: a list
represents an internal node, the ﬁrst element of the list the node type, and the remainder of the elements
the node’s children. For example, consider the following variable declaration in C:
int var;
The root node of the abstract syntax tree (AST) for this statement is a declaration node; the children of the
root node are the type int and the variable reference var. One could represent this AST using S-expressions
like so:
(declare var int)
And it so happens that this is the exact syntax for variable declarations in C-Lisp.
Most expression opcodes in C-Lisp (i.e. directives that specify some computation) exhibit a close correspon-
dence to instruction opcodes in the LLVM IR, in that they perform the same operations and take the same
kinds of arguments. For example, the LLVM IR implements the fadd opcode for integer addition, with the
syntax
<result> = fadd [fast-math flags]* <ty> <op1>, <op2>
C-Lisp exposes a single form of this instruction, consisting of the compulsory operands, through its fadd
expression opcode:
(fadd <op1> <op2>)
1
Owing to the adoption of C semantics, it can be noted that the result is not speciﬁed in the fadd expression;
the set opcode fulﬁlls that purpose, and can be used with the fadd expression as an operand. Additionally,
the type is inferred, not explicitly stated.
As an illustration of C-Lisp, consider the following C function to add the product of two numbers to the
contents of a pointer. The function returns nothing, takes one pointer to a 64-bit integer and two 32-bit
integers as arguments (the bit widths are platform-speciﬁc, but we shall assume these).
void muladd (long int * res, int a, int b) {
int mul_res = a * b;
*res = *res + mul_res;
}
An equivalent C-Lisp implementation would be:
(define ((muladd void) (res (ptr int64)) (a int) (b int))
(declare mul_res int)
(set mul_res (mul a b))
(store res (add (load res) (sext mul_res int64))))
On the face of it, there is a world of diﬀerence between the two versions. However, on closer observation, the
C-Lisp version closely resembles the AST of the C version. Consider the assignment of mul_res in C: it is
an assignment expression with mul_res as its ﬁrst operand and a * b as its second. Further recursing into
the second operand, it is a multiplication expression with a and b as operands. The C-Lisp version reﬂects
this structure accurately, with set denoting an assignment and mul denoting a multiplication.
As a result, both implementations have similar semantics, and the executables produced from both per-
form equally well. However, the adoption of S-expressions makes it much more conducive to generate and
programmatically interact with the C-Lisp version.
One main point of diﬀerence between semantics of two versions is the use of implicit casting. The C version
adds mul_res, a 32-bit integer, to the contents of res, a 64-bit integer. This works because a compliant C
compiler will insert an implicit cast from a 32- to a 64-bit integer, and thus behave as if the source program
had stated
*res = *res + (long int) mul_res;
C-Lisp, on the other hand, employs no implicit action whatsoever. The programmer is forced to explicitly
cast mul_res to a 64-bit integer. This helps keep the C-Lisp language’s implementation concise and simple.
Additionally, the absence of implicit actions simpliﬁes the analysis of these programs.
To ease the process of C-Lisp code generation, the JavaScript Object Notation (JSON) is used as an exchange
format for C-Lisp.
JSON has support for lists as well as the basic token types (integers, ﬂoating-point
numbers and so on), which makes it an ideal choice for serializing S-expressions. Additionally, JSON enjoys
support in most mature programming languages. The transformer from S-expression to JSON is written in
Guile Scheme, and as such uses most of Scheme’s conventions for capturing constructs such as unquote.
2. A Macro Preprocessor
C-Lisp is intended to be minimal; most computation can be expressed in C-Lisp with reasonably simple
code, and there is seldom more than one way to do so. This necessitates a strong macro system: one that
enables extensions of C-Lisp, reducing the need for feature additions to the language. Prelisp aims to fulﬁll
this need, borrowing from the multistage programming [5] paradigm.
Prelisp uses Python as the macro language, although any modern general-purpose language could have been
used. On the face of it, using a third-party language for the preprocessor can make for rather complicated
macro deﬁnitions; however, owing to the adoption of the S-expression syntactical form, the process of C-
Lisp code generation is greatly simpliﬁed.
Thus, Python’s own list data structure make it feasible to
programmatically emit C-Lisp code. Additionally, Python makes for a good choice because it involves a
2
minimal learning curve, and it leaves a powerful standard library and programming environment at the
macro programmer’s disposal.
The Prelisp preprocessor takes the input program as a JSON object. Portions of this object are recognized as
macro expressions, evaluated using macro deﬁnitions from a supplied Python module (the “macro module”
henceforth), and replaced to produce the result. A macro is expected to be deﬁned in the global scope of
the macro module, and is either referenced directly, like a variable, or called, like a function. In both cases,
the macro evaluates to a Python object which is substituted in place of the macro expression and eventually
serialized back into JSON along with the rest of the program. Macro expressions in the source program are
denoted using either the unquote or the unquote-splicing constructs [6], borrowed from the Lisp family.
2.1. Variable substitution
unquote can be used to substitute a single expression. The following expression
; In the source program
(eq (call getchar) ,EOF)
is equivalent to the S-expression
(eq (call getchar) (unquote EOF))
and thus is represented in JSON as
["eq", ["call", "getchar"], ["unquote", "EOF"]]
Given this macro expression, Prelisp recognizes EOF as the unquoted expression and looks for an object
named EOF in the global scope of the macro module. With the following deﬁnition in the macro module
# In the macro module
EOF = ["trunc", -1, "int8"]
the macro expression evaluates to
["eq", ["call", "getchar"],
["trunc", -1, "int8"]]
and when converted back to S-expression form yields
(eq (call getchar) (trunc -1 int8))
2.2. Parametric macros
Consider a function call-like macro expression:
; In the source program
,(incr var 45)
with the equivalent JSON form:
["unquote", ["incr", "var", 45]]
and a corresponding deﬁnition in the macro module:
# In the macro module
def incr (name, amt)
"""(incr name, amt) -> (set name (add name amt))"""
return ["set", name, ["add", name, amt]]
Since the expression after unquote is a list, Prelisp infers incr to be the name of a callable in the macro
module. The macro is evaluated by calling incr with arguments "var" and 45, and the resulting macro
substitution’s JSON form looks like this:
["set", "var", ["add", "var", 45]]
When converted back to the S-expression form:
3
(set var (add var 45))
2.3. Splicing macros
unquote-splicing can be used to substitute multiple expressions in place of a single macro expression. An
expression of the form
; In the source program
,@(declare_multiple (ch i) int)
is represented in JSON as
["unquote-splicing", ["declare_multiple", ["ch", "i"], "int"]]
Given the following macro deﬁnition,
# In the macro module
def declare_multiple(names, typ):
decls = []
for name in names:
decls.append(["declare", name, typ])
return decls
The macro expression is replaced with
["declare", "ch", "int"]
["declare", "i", "int"]
Thus, in S-expression, this looks like
(declare ch int)
(declare i int)
Note that if unquote (i.e. , instead of ,@) was used, both of the declare statements would be nested under
a list, like so:
((declare ch int)
(declare i int))
Note that the return values of incr and declare_multiple are entirely composed of native Python data
structures, and the literal expressions used to construct the return values closely resemble the actual S-
expressions that are emitted. This highlights the ease of C-Lisp code generation.
3. Example: Building an FFI System using Prelisp
C-Lisp is compatible with C at the ABI level. This means that libraries that can be used with C code
can also be used with C-Lisp in a similar fashion. In C, using an external library typically involves placing
forward deﬁnitions for the library’s contents in the source program, and linking to the library’s object ﬁle;
the same holds for C-Lisp too.
Libraries are typically distributed along with header ﬁles containing forward declarations for their contents.
C’s #include preprocessor directive is typically the mechanism by which the forward declarations from these
header ﬁles are brought into the source of a program that uses the library. Since C-Lisp uses C’s data types,
it is feasible to generate forward declarations in C-Lisp from forward declarations in C; consequently, a
library’s C header ﬁles can be used to generate C-Lisp bindings to the library.
Prelisp makes it possible to implement a solution for binding generation entirely in Python and expose it as
a macro for use in a C-Lisp program. Such a solution is under active development, and is already in use by
a test program that launches accelerated vector addition on an NVIDIA GPU using the CUDA driver API.
Parsing C is a relatively complex task, partly due to C’s complicated syntax, and partly due to the presence
of constructs in the C language that are outside the scope of C-Lisp — typedef, enum, and so on. For
4
these reasons, the actual parsing of C code is oﬄoaded to the Clang frontend. Clang is used to produce two
artifacts from a C header: the LLVM IR module and the AST in Clang’s own JSON schema. The LLVM
IR is then parsed using Numba’s [7] LLVMLite binding layer to yield function declarations and struct type
deﬁnitions (collectively referred to as “signatures” henceforth), while type aliases (typedefs) are scraped
from the JSON AST.
The binding generation process works on this premise. A Python module orchestrates the processes of running
the Clang executable, saving its outputs, and processing the LLVM IR and the AST to yield declarations in
C-Lisp. The process is as follows:
• Take input for desired headers, functions, structs and typedefs
• Generate a C program that
– includes the desired header ﬁles
– uses each of the desired functions and structs
• Compile the generated C program, saving its JSON AST and LLVM IR
• Parse the IR to extract function and struct type signatures
• Parse the JSON AST to extract typedef type aliases and function parameter names
This same module, when used as a Prelisp macro module, serves as a convenient means of using deﬁnitions
from external libraries. At present, its usage on the CUDA driver API is a single macro call:
,@(include
(/usr/local/cuda/include/cuda.h) ; Headers
(cuInit
cuDeviceGetCount
cuDeviceGet
cuCtxCreate_v2
cuModuleLoadDataEx
cuModuleGetFunction
cuMemAlloc_v2
cuMemcpyHtoD_v2
cuLaunchKernel
cuCtxSynchronize
cuMemcpyDtoH_v2
cuMemFree_v2
cuModuleUnload
cuCtxDestroy_v2) ; Functions
() ; Structs
(CUcontext CUmodule CUfunction CUstream CUdevice)) ; Typedefs
And this allows access to the CUDA driver API through rather familiar names:
(declare module ,CUmodule)
(declare kernel_func ,CUfunction)
; ...
(call cuModuleGetFunction (ptr-to kernel_func) module "kernel")
For reference, the equivalent C version would look like this:
#include <cuda.h>
CUmodule module;
CUfunction kernel_func;
// ...
cuModuleGetFunction(&kernel_func, module, "kernel");
5
4. Conclusion
The implementation of the Prelisp preprocessor system is a rather straightforward extension of the ideas
it builds on, such as S-expression IRs and substitution using unquote. However, the combination of these
ideas results in a powerful framework that made it possible to achieve on-the-ﬂy bindings generation and
inclusion with a few lines of Python code and minimal external dependencies.
5. References
1. The Llama.lisp Compiler Framework. https://github.com/chsasank/llama.lisp
2. Dijkstra, Edsger W. “Letters to the editor: go to statement considered harmful.” Communications of
the ACM 11.3 (1968): 147-148.
3. Lattner, Chris, and Vikram Adve. “LLVM: A compilation framework for lifelong program analysis
& transformation.” International symposium on code generation and optimization, 2004. CGO 2004..
IEEE, 2004.
4. Kernighan, Brian W., and Dennis M. Ritchie. The C programming language. prentice-Hall, 1988.
5. Taha, Walid. “A gentle introduction to multi-stage programming.” Domain-Speciﬁc Program Genera-
tion: International Seminar, Dagstuhl Castle, Germany, March 23-28, 2003. Revised Papers. Berlin,
Heidelberg: Springer Berlin Heidelberg, 2004.
6. Bawden, Alan. “Quasiquotation in Lisp.” PEPM. 1999.
7. Lam, Siu Kwan, Antoine Pitrou, and Stanley Seibert. “Numba: A llvm-based python jit compiler.”
Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC. 2015.
6
